{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqwaPR+DSQgUipzn5LPJRq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Aim : NLP preprocessing techniques implementation (Tokenization, punctuation removal, Stop\n","words removal, Stemming, and Lemmatization)"],"metadata":{"id":"sXB1wSi1lTg1"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9-BgzyYhDtb","executionInfo":{"status":"ok","timestamp":1729270338011,"user_tz":-330,"elapsed":7267,"user":{"displayName":"Achyut Shinde","userId":"02380621302582895872"}},"outputId":"be3e8ec7-8c01-4d37-f312-96858dc495af"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","import string\n","\n","text = \"Natural Language Processing with Python is interesting! It includes techniques like Tokenization, Stemming, and Lemmatization.\"\n","\n","#tokenizing\n","tokens = word_tokenize(text)\n","print(\"Tokens:\", tokens)\n","\n","#punctuation removal\n","tokens_no_punct = [word for word in tokens if word not in string.punctuation]\n","print(\"After Punctuation Removal:\", tokens_no_punct)\n","\n","#Stop-words removal\n","stop_words = set(stopwords.words('english'))\n","tokens_no_stopwords = [word for word in tokens_no_punct if word.lower() not in stop_words]\n","print(\"After Stop Words Removal:\", tokens_no_stopwords)\n","\n","#stemming\n","stemmer = PorterStemmer()\n","stemmed_words = [stemmer.stem(word) for word in tokens_no_stopwords]\n","print(\"After Stemming:\", stemmed_words)\n","\n","#lemmatization\n","doc = nlp(' '.join(tokens_no_stopwords))\n","lemmatized_words = [token.lemma_ for token in doc]\n","print(\"After Lemmatization:\", lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qikmuMUUhwOp","executionInfo":{"status":"ok","timestamp":1729270952627,"user_tz":-330,"elapsed":1339,"user":{"displayName":"Achyut Shinde","userId":"02380621302582895872"}},"outputId":"d82c243e-3f66-4c84-e449-5c9c79741973"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens: ['Natural', 'Language', 'Processing', 'with', 'Python', 'is', 'interesting', '!', 'It', 'includes', 'techniques', 'like', 'Tokenization', ',', 'Stemming', ',', 'and', 'Lemmatization', '.']\n","After Punctuation Removal: ['Natural', 'Language', 'Processing', 'with', 'Python', 'is', 'interesting', 'It', 'includes', 'techniques', 'like', 'Tokenization', 'Stemming', 'and', 'Lemmatization']\n","After Stop Words Removal: ['Natural', 'Language', 'Processing', 'Python', 'interesting', 'includes', 'techniques', 'like', 'Tokenization', 'Stemming', 'Lemmatization']\n","After Stemming: ['natur', 'languag', 'process', 'python', 'interest', 'includ', 'techniqu', 'like', 'token', 'stem', 'lemmat']\n","After Lemmatization: ['Natural', 'Language', 'Processing', 'Python', 'interesting', 'include', 'technique', 'like', 'Tokenization', 'Stemming', 'Lemmatization']\n"]}]}]}